{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "LciKvMEzH9I-"
   },
   "outputs": [],
   "source": [
    "import sqlite3 as sql\n",
    "from contextlib import closing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time as tm\n",
    "import pickle\n",
    "import os\n",
    "import csv\n",
    "import importlib\n",
    "import execute  # Import module without specifying the function\n",
    "importlib.reload(execute)  # Force reload\n",
    "import index  # Import module without specifying the function\n",
    "importlib.reload(index) # Force reload\n",
    "from execute import my_execute\n",
    "from index import my_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GGdRLObRKAlM"
   },
   "source": [
    "sqlite3 does not support contextual closing natively (yet). Using a super-elegant workaround proposed by erlendaasland\\\n",
    "https://discuss.python.org/t/implicitly-close-sqlite3-connections-with-context-managers/33320/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "POoHIPqtIbVz"
   },
   "outputs": [],
   "source": [
    "def safe_tran( db_name, query ):\n",
    "  with closing( sql.connect( db_name ) ) as conn:\n",
    "    cur = conn.execute( query )\n",
    "    cols = [ col[0] for col in cur.description ]\n",
    "    df = pd.DataFrame.from_records( cur, columns = cols )\n",
    "    return df\n",
    "\n",
    "\n",
    "db_name = \"public.db\"\n",
    "get_gold_results = lambda query: safe_tran( db_name, query )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "EY9Q-50DKTdE"
   },
   "outputs": [],
   "source": [
    "def make_sqlite_query( clause ):\n",
    "  query = \"SELECT id FROM tbl WHERE \"\n",
    "  query += \" AND \".join( [ ' '.join( pred ) for pred in clause ] )\n",
    "  return query\n",
    "\n",
    "def eval_results( clause, disk, idx_stat ):\n",
    "  # Execute the query on an actual DB\n",
    "  df_gold = get_gold_results( make_sqlite_query( clause ) )\n",
    "\n",
    "  # Execute the query using the index and time it\n",
    "  tic = tm.perf_counter()\n",
    "  diskloc_list = my_execute( clause, idx_stat )\n",
    "  toc = tm.perf_counter()\n",
    "  t_idx = toc - tic\n",
    "\n",
    "  # Do sanity checks on the returned locations -- dont want any buffer overflow attacks :)\n",
    "  diskloc_list = np.minimum( np.maximum( diskloc_list, 0 ), len( disk ) - 1 )\n",
    "\n",
    "  # Find the seek and read time requried to retrieve records from the virtual disk\n",
    "  diffs = diskloc_list[ 1: ] - diskloc_list[ :-1 ]\n",
    "  # Take care of cases where we need to loop back to reach a record\n",
    "  diffs[ diffs <= 0 ] += len( disk )\n",
    "  t_seek = diffs.sum()\n",
    "  t_read = len( diskloc_list )\n",
    "  # Sanity check\n",
    "  assert( t_seek >= t_read - 1 )\n",
    "  t_seek -= t_read - 1\n",
    "  # Take care of pesky edge cases\n",
    "  if t_read == 0:\n",
    "    t_seek = 0\n",
    "\n",
    "  # Get hold of the tuples chosen by the index from the virtual disk\n",
    "  response_stu = []\n",
    "  # print(type(disk))\n",
    "  # print(type(diskloc_list))\n",
    "  if len( diskloc_list ) > 0:\n",
    "    response_stu = disk[ diskloc_list ]\n",
    "  df_stu = pd.DataFrame( response_stu, columns = [ \"id\" ] )\n",
    "\n",
    "  # Rename columns just to be safe so as to enable merging\n",
    "  df_stu.rename( dict( zip( df_stu.columns, df_gold.columns ) ), axis = 1, inplace = True )\n",
    "  \n",
    "  \n",
    "  union = pd.merge( df_gold, df_stu, how = \"outer\", indicator = True )\n",
    "  inter = pd.merge( df_gold, df_stu, how = \"inner\", indicator = True )\n",
    "  \n",
    "  # Assuming 'union' already includes the '_merge' column\n",
    "  # difference = union[union['_merge'] != 'both']\n",
    "  # print(difference)\n",
    "\n",
    "\n",
    "\n",
    "  # If the gold response is not empty, use intersection over union score\n",
    "  # Since union removes duplicates, consider length of diskloc_list as well\n",
    "  if len( df_gold ) > 0:\n",
    "    score = round( len( inter ) / max( len( diskloc_list ), len( union ) ), 2 )\n",
    "  # If the gold response itself is empty, penalize non-empty response by index\n",
    "  elif len( df_gold ) == 0:\n",
    "    score = round( 1 / ( 1 + len( diskloc_list ) ), 2 )\n",
    "\n",
    "  # if score != 1:\n",
    "  #   print(clause)\n",
    "\n",
    "  return t_idx, t_seek, t_read, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "KeLLNTmoVB9U"
   },
   "outputs": [],
   "source": [
    "n_trials = 3\n",
    "\n",
    "t_build = 0\n",
    "disk_size = np.int64(0)\n",
    "idx_size = 0\n",
    "t_idx = 0\n",
    "t_seek = np.int64(0)\n",
    "t_read = np.int64(0)\n",
    "score = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "8heZOUbvWkbe"
   },
   "outputs": [],
   "source": [
    "# Read the data to be indexed\n",
    "with open( \"public.csv\", 'r' ) as csvfile:\n",
    "  reader = csv.reader( csvfile )\n",
    "  tuples = [ ( int( row[ 0 ] ), row[ 1 ], int( row[ 2 ] ) ) for row in reader ]\n",
    "\n",
    "# Create proper predicates out of CSV data\n",
    "def make_predicates( tok_list ):\n",
    "  if len( tok_list ) == 3:\n",
    "    return [ tok_list ]\n",
    "  if len( tok_list ) == 6:\n",
    "    return [ tok_list[ :3 ], tok_list[ 3: ] ]\n",
    "\n",
    "# Read the clauses that will constitute the evaluation queries\n",
    "with open( \"clauses.csv\", 'r' ) as csvfile:\n",
    "  reader = csv.reader( csvfile )\n",
    "  c_list = [ make_predicates( row ) for row in reader ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "PiB-skm2VXFZ"
   },
   "outputs": [],
   "source": [
    "for t in range( n_trials ):\n",
    "  tic = tm.perf_counter()\n",
    "  disk, idx_stat = my_index( tuples )\n",
    "  disk = np.array( disk )\n",
    "  toc = tm.perf_counter()\n",
    "  t_build += toc - tic\n",
    "\n",
    "  disk_size += len( disk )\n",
    "\n",
    "  with open( f\"idx_dump_{t}.pkl\", \"wb\" ) as outfile:\n",
    "    pickle.dump( idx_stat, outfile, protocol=pickle.HIGHEST_PROTOCOL )\n",
    "\n",
    "  idx_size += os.path.getsize( f\"idx_dump_{t}.pkl\" )\n",
    "  # print(idx_stat)\n",
    "  for clause in c_list:\n",
    "    t_i, t_s, t_r, scr = eval_results( clause, disk, idx_stat )\n",
    "    t_idx += t_i\n",
    "    t_seek += t_s\n",
    "    t_read += t_r\n",
    "    score += scr\n",
    "    # if scr != 1:\n",
    "    #   print(clause)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tXvUu6PhW8p_",
    "outputId": "edae3aba-c5f4-4228-c019-8f81f4d6582f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.773230233346112 200000.0 31822556.0 0.03641823349365344 2227760.0 1400713.0 1.0\n"
     ]
    }
   ],
   "source": [
    "t_build /= n_trials\n",
    "disk_size /= n_trials\n",
    "idx_size /= n_trials\n",
    "t_idx /= n_trials\n",
    "t_seek /= n_trials\n",
    "t_read /= n_trials\n",
    "score /= n_trials\n",
    "score /= len( c_list )\n",
    "\n",
    "print( t_build, disk_size, idx_size, t_idx, t_seek, t_read, score )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.22813676666313162 300000.0 2861000.0 3.787527566673816 6400303.0 1400713.0 1.0\n",
    "0.21858643333447011 300000.0 2861000.0 3.9164780333449016 6400303.0 1400713.0 1.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Disk size is 300000 because ids are stored 3 times: sorted by id, by name, by year\n",
    "2. Index size is high because we have stored entire tuples in idx_stat returned by my_index()\n",
    "3. Score is 1.0 indicating 100% accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----------------- END ------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below cells are for individual clause testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_clause = [['name', 'LIKE', \"'so%'\"], ['year', '>=', '1996']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3 as sql\n",
    "from contextlib import closing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time as tm\n",
    "import pickle\n",
    "import os\n",
    "import csv\n",
    "import importlib\n",
    "import execute  # Import module without specifying the function\n",
    "importlib.reload(execute)  # Force reload\n",
    "import index  # Import module without specifying the function\n",
    "importlib.reload(index) # Force reload\n",
    "from execute import my_execute\n",
    "from index import my_index\n",
    "\n",
    "t_build = 0\n",
    "disk_size = np.int64(0)\n",
    "idx_size = 0\n",
    "t_idx = 0\n",
    "t_seek = np.int64(0)\n",
    "t_read = np.int64(0)\n",
    "score = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below cells are to check disk locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_i, t_s, t_r, scr = eval_results( ind_clause , disk, idx_stat )"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
